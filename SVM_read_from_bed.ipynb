{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a029acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# path to pickle file containing a dictionary with illumina data preprocessed\n",
    "file_path = 'data/no_strand_all_points_dict.pickle'\n",
    "\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    epi_signatures_all = pickle.load(file)\n",
    "\n",
    "print(epi_signatures_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad24fe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_bed_files(input_path):\n",
    "    bed_files = {}\n",
    "    \n",
    "    # Get a list of all files in the input folder\n",
    "    files = os.listdir(input_path)\n",
    "    sorted_files = sorted(files)\n",
    "    # Iterate over each file and read the bedfiles \n",
    "    for file_name in sorted_files:\n",
    "\n",
    "        if file_name.endswith('.bed'):\n",
    "            file_path = os.path.join(input_path, file_name)\n",
    "            \n",
    "            # Read the contents of the bedmethyl file using pandas (first 3 columsn chr start end and methylation column 14th position)\n",
    "            bed_df = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "            bed_df = (bed_df[[0, 1, 2, 13]]).reset_index(drop=True)\n",
    "            bed_df = bed_df.rename(columns={0: 'Chr', 1: 'Start', 2: 'End', 13 : 'Methylation'})\n",
    "         \n",
    "            file_basename = os.path.splitext(file_name)[0]   \n",
    "            bed_files[file_basename] = bed_df\n",
    "    \n",
    "    return bed_files\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57845911",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_path = 'path/to/folder/with/beds'\n",
    "result = read_bed_files(input_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ac4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for disorder in result:\n",
    "        df = result[disorder]\n",
    "        df['Methylation'] = df['Methylation'].replace('.', np.nan)\n",
    "        df['Methylation'] = pd.to_numeric(df['Methylation'] , errors='coerce')\n",
    "        df['Methylation'] = df['Methylation']/100\n",
    "        result[disorder]=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931edc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#link nanopore methylation data to the correct disorder\n",
    "epi_signatures_all_with_sample = epi_signatures_all.copy()\n",
    "\n",
    "epi_signatures_all_with_sample['MRXCJS'] = epi_signatures_all_with_sample['MRXSCJ']\n",
    "del epi_signatures_all_with_sample['MRXSCJ']\n",
    "for disorder in epi_signatures_all_with_sample:\n",
    "    epi_signatures_all_with_sample[disorder] = epi_signatures_all_with_sample[disorder].iloc[:, 2:-1]\n",
    "    for file_basename in result:\n",
    "        print(file_basename)\n",
    "        if file_basename.startswith(disorder):\n",
    "            epi_signatures_all_with_sample[disorder] = epi_signatures_all_with_sample[disorder].assign(**{file_basename: list(result[file_basename]['Methylation'])})\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965903c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#get number of samples that you read \n",
    "n_of_samples = len(epi_signatures_all_with_sample['Sotos'].columns[35:])\n",
    "\n",
    "samples=epi_signatures_all_with_sample['Sotos'].columns[35:]\n",
    "# use map to remove 'Sotos_' prefix from each string and retain only the sample names\n",
    "samples = list(map(lambda col: col.replace('Sotos_', ''), samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab0cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "filter_df = pd.DataFrame()\n",
    "pred_df = pd.DataFrame()\n",
    "order_disorders = []\n",
    "\n",
    "for disorder in epi_signatures_all_with_sample:\n",
    "    if (disorder != 'Controls'):\n",
    "        \n",
    "        X = epi_signatures_all_with_sample[disorder].T\n",
    "        y = X.index.tolist()\n",
    "\n",
    "        if (disorder != 'MRXCJS'):\n",
    "            new_y = [1 if item == str(disorder) else 0 for item in y]\n",
    "        else:\n",
    "            new_y = [1 if item == 'MRXSCJ' else 0 for item in y]\n",
    "\n",
    "        # Convert 'NA' values to NaN and Fill NaN values with column averages\n",
    "        X = X.replace('NA', np.nan)\n",
    "        X = X.astype(float)\n",
    "        X = X.fillna(X.mean())\n",
    "        \n",
    "        \n",
    "        #take for training always the first 35 samples representing the illumina data\n",
    "        #take for testing always our nanopore samples\n",
    "        X_train = X.iloc[:-n_of_samples, :]\n",
    "        X_test = X.iloc[-n_of_samples:, :]\n",
    "\n",
    "        y_train = new_y[:-n_of_samples]\n",
    "        y_test = new_y[-n_of_samples:]\n",
    "        \n",
    "        #weights for classes\n",
    "        class_weights = {0: 1, 1: 10}  # Example weights, adjust as needed\n",
    "        \n",
    "        # Create SVM classifiers \n",
    "        linear_classifier = svm.SVC(kernel='linear', class_weight=class_weights)\n",
    "        \n",
    "\n",
    "        #Train the classifiers for the current disorder\n",
    "        linear_classifier.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "        # Make predictions using the trained classifiers\n",
    "        linear_pred = linear_classifier.predict(X_test)\n",
    "       \n",
    "        #store the prediction results of every SVM\n",
    "        new_row_df = pd.DataFrame([linear_pred])\n",
    "        pred_df =  pd.concat([pred_df,new_row_df], ignore_index=True)\n",
    "        #store the order in which the disorder specific SVMs were trained and tested\n",
    "        order_disorders.append(disorder)\n",
    "        \n",
    "        #store decision function value for every SVM - this will be used to determine the samples correct class\n",
    "        decision_values = linear_classifier.decision_function(X_test)\n",
    "        new_row_df = pd.DataFrame([decision_values])\n",
    "        filter_df = pd.concat([filter_df,new_row_df], ignore_index=True)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f56bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df.index = order_disorders\n",
    "filter_df.columns = samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c10f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum value and corresponding row name of column 'A' using idxmax() \n",
    "#highest confidence score (decision function value) for the classification of every sample\n",
    "for sample in range(0,n_of_samples):\n",
    "    max_value = filter_df.iloc[:,sample].max()\n",
    "    row_name = filter_df.iloc[:,sample].idxmax()\n",
    "\n",
    "    # Print the maximum value and row name\n",
    "    print( samples[sample])\n",
    "    if (max_value == -1000 or max_value < 0.35):\n",
    "        row_name = 'Control'\n",
    "    print('Max value:', max_value, 'Assigned Class:', row_name)\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
